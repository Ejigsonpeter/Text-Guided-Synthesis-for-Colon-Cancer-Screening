{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3524c7d-0118-405e-9085-e1e5042984fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'diffusers' already exists and is not an empty directory.\n",
      "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers\n",
    "!cd diffusers\n",
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c0e3b7-2d45-4d1c-9059-e425759ad711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.16.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 1)) (0.30.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 3)) (4.41.2)\n",
      "Requirement already satisfied: datasets>=2.19.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.19.2)\n",
      "Collecting ftfy (from -r diffusers/examples/text_to_image/requirements.txt (line 5))\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorboard (from -r diffusers/examples/text_to_image/requirements.txt (line 6))\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: Jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from -r diffusers/examples/text_to_image/requirements.txt (line 7)) (3.1.4)\n",
      "Collecting peft==0.7.0 (from -r diffusers/examples/text_to_image/requirements.txt (line 8))\n",
      "  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (4.66.4)\n",
      "Requirement already satisfied: safetensors in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.23.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (10.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (69.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.7.0->-r diffusers/examples/text_to_image/requirements.txt (line 8)) (0.43.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (3.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers>=4.25.1->-r diffusers/examples/text_to_image/requirements.txt (line 3)) (0.19.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (3.9.5)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ftfy->-r diffusers/examples/text_to_image/requirements.txt (line 5)) (0.2.13)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.63.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6))\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (3.20.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r diffusers/examples/text_to_image/requirements.txt (line 6))\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from Jinja2->-r diffusers/examples/text_to_image/requirements.txt (line 7)) (2.1.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->torchvision->-r diffusers/examples/text_to_image/requirements.txt (line 2)) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets>=2.19.1->-r diffusers/examples/text_to_image/requirements.txt (line 4)) (2024.1)\n",
      "Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: werkzeug, tensorboard-data-server, markdown, ftfy, tensorboard, peft\n",
      "Successfully installed ftfy-6.2.0 markdown-3.6 peft-0.7.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 werkzeug-3.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r diffusers/examples/text_to_image/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef3eace-8ae5-439c-bab6-cbf8931ac22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jupyter/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    }
   ],
   "source": [
    "!accelerate config default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4005b347-b870-4d2f-86a4-d1eb8e6a273c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d5dbdc5-0260-4905-85a0-20825af07008",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e390728f5b9e4e838b3f815bd8cd3c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Login to Hugging Face\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8226414a-1510-41f8-a2a3-ec41c0ac7658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "dataset_name=\"colonoscopy_data_for_vqa\"\n",
    "OUTPUT_DIR=\"new_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30482088-f467-419e-87c2-7e955fd1cdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
      "06/04/2024 20:55:00 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 4\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "06/04/2024 20:55:00 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 4\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "06/04/2024 20:55:00 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 4\n",
      "Process index: 2\n",
      "Local process index: 2\n",
      "Device: cuda:2\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "06/04/2024 20:55:00 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 4\n",
      "Process index: 3\n",
      "Local process index: 3\n",
      "Device: cuda:3\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "{'variance_type', 'rescale_betas_zero_snr', 'thresholding', 'clip_sample_range', 'sample_max_value', 'prediction_type', 'dynamic_thresholding_ratio', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'latents_std', 'norm_num_groups', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'time_cond_proj_dim', 'addition_time_embed_dim', 'reverse_transformer_layers_per_block', 'timestep_post_act', 'conv_out_kernel', 'encoder_hid_dim', 'resnet_skip_time_act', 'upcast_attention', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'only_cross_attention', 'time_embedding_type', 'conv_in_kernel', 'cross_attention_norm', 'mid_block_only_cross_attention', 'resnet_out_scale_factor', 'resnet_time_scale_shift', 'attention_type', 'use_linear_projection', 'dropout', 'dual_cross_attention', 'addition_embed_type', 'transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'class_embeddings_concat', 'class_embed_type', 'num_class_embeds', 'mid_block_type', 'time_embedding_dim', 'num_attention_heads'} was not found in config. Values will be initialized to default values.\n",
      "{'time_cond_proj_dim', 'addition_time_embed_dim', 'reverse_transformer_layers_per_block', 'timestep_post_act', 'conv_out_kernel', 'encoder_hid_dim', 'resnet_skip_time_act', 'upcast_attention', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'only_cross_attention', 'time_embedding_type', 'conv_in_kernel', 'cross_attention_norm', 'mid_block_only_cross_attention', 'resnet_out_scale_factor', 'resnet_time_scale_shift', 'attention_type', 'use_linear_projection', 'dropout', 'dual_cross_attention', 'addition_embed_type', 'transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'class_embeddings_concat', 'class_embed_type', 'num_class_embeds', 'mid_block_type', 'time_embedding_dim', 'num_attention_heads'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|█████████████| 1890/1890 [00:00<00:00, 374226.25it/s]\n",
      "Resolving data files: 100%|█████████████| 1890/1890 [00:00<00:00, 365866.74it/s]\n",
      "Resolving data files: 100%|█████████████| 1890/1890 [00:00<00:00, 344512.58it/s]\n",
      "Resolving data files: 100%|█████████████| 1890/1890 [00:00<00:00, 381043.77it/s]\n",
      "06/04/2024 20:55:10 - INFO - __main__ - ***** Running training *****\n",
      "06/04/2024 20:55:10 - INFO - __main__ -   Num examples = 1889\n",
      "06/04/2024 20:55:10 - INFO - __main__ -   Num Epochs = 1\n",
      "06/04/2024 20:55:10 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "06/04/2024 20:55:10 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "06/04/2024 20:55:10 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "06/04/2024 20:55:10 - INFO - __main__ -   Total optimization steps = 100\n",
      "Steps:   0%|                  | 0/100 [00:03<?, ?it/s, lr=1e-5, step_loss=0.161]/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "Steps:   1%|          | 1/100 [00:06<09:50,  5.96s/it, lr=1e-5, step_loss=0.183]06/04/2024 20:55:16 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "06/04/2024 20:55:16 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "06/04/2024 20:55:16 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "06/04/2024 20:55:16 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\n",
      "Steps: 100%|███████| 100/100 [08:06<00:00,  4.85s/it, lr=1e-5, step_loss=0.0109]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "\n",
      "Loading pipeline components...:  14%|█▊           | 1/7 [00:00<00:01,  4.60it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:00<00:00, 24.13it/s]\n",
      "Configuration saved in city-building-model/vae/config.json\n",
      "Model weights saved in city-building-model/vae/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in city-building-model/unet/config.json\n",
      "Model weights saved in city-building-model/unet/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in city-building-model/scheduler/scheduler_config.json\n",
      "Configuration saved in city-building-model/model_index.json\n",
      "Steps: 100%|███████| 100/100 [08:14<00:00,  4.94s/it, lr=1e-5, step_loss=0.0109]\n"
     ]
    }
   ],
   "source": [
    "# The --use_8bit_adam flag is crucial to be able to train on the T4 GPU which has only 15GB of memory\n",
    "!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --dataset_name=$dataset_name \\\n",
    "  --use_ema \\\n",
    "  --use_8bit_adam \\\n",
    "  --resolution=512 --center_crop --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --max_train_steps=100 \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=\"model1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "292206e9-5f90-4a98-a4d9-357a5b505656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f16651614d4fa3acfe0d8bae21b1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ae4ac32a2a49b9a490673d0ed3ac4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "model_path = \"finetuned-stable-diffusion\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(prompt=\"Generate an image with an an abnormality located in the center, upper-left, upper-right, lower-left, lower-right, center-left, center-right, upper-center and lower-center.\").images[0]\n",
    "image.save(\"gen-finetuned.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef927762-5621-4136-94f8-3342736d95d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Set up the pipeline\n",
    "model_path = \"finetuned-stable-diffusion\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Define file paths\n",
    "prompt_file_path = \"ImageCLEFmed-MEDVQA-GI-2024-Testing-Propmpts.txt\"\n",
    "output_folder = \"synthetic\"\n",
    "csv_file_path = \"prompt_and_data.csv\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Open the prompt file and read prompts\n",
    "with open(prompt_file_path, 'r') as file:\n",
    "    prompts = file.readlines()\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['prompt', 'image_name', 'image_path']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Generate images for each prompt and save them\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        prompt = prompt.strip()\n",
    "        if prompt:  # Check if prompt is not empty\n",
    "            image = pipe(prompt=prompt).images[0]\n",
    "            image_name = f\"gen-finetuned-{i+1}.png\"\n",
    "            image_path = os.path.join(output_folder, image_name)\n",
    "            image.save(image_path)\n",
    "\n",
    "            # Write prompt and image details to the CSV file\n",
    "            writer.writerow({'prompt': prompt, 'image_name': image_name, 'image_path': image_path})\n",
    "\n",
    "print(\"Image generation complete. Prompts and image data saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c5059-0e2c-4a7f-8712-aa21094d8f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
